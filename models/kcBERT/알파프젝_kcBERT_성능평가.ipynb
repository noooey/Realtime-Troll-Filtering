{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVPq3_bSRBTb",
        "outputId": "7970213a-7e76-43d7-c909-6bfb2a592659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKNvcg8ORpHu"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPO6wb-eVOrJ"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/jason9693/Soongsil-BERT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cJMTMMjVxvG",
        "outputId": "22c5efd9-d810-4f47-c93c-4cb6ccab03c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Soongsil-BERT/finetune'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd Soongsil-BERT/finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfKSijrzoCvZ",
        "outputId": "f4fad3af-25ec-47c3-936a-ab20f695c2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.8ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.8.2-0ubuntu2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install build-essential\n",
        "!sudo apt-get install python3-dev\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMpcvvVDNuxU",
        "outputId": "e12b5fdd-b633-45fe-e316-51389f440a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tokenizers==0.5.2\n",
            "  Using cached tokenizers-0.5.2.tar.gz (64 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tokenizers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers==0.5.2\n",
        "!pip install --upgrade transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_YmmXjhbQZK",
        "outputId": "8fba9fa1-7a77-4dd4-b53a-49ea24962862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: soynlp in /usr/local/lib/python3.10/dist-packages (0.0.493)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.22.4)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from soynlp) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install soynlp emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2PgqQTtf10Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "from sklearn import metrics as sklearn_metrics\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    \n",
        "    AdamW,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_LZQmxNgWpY",
        "outputId": "2ffca88e-2201-434b-ca35-b46c2adfe345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "n_devices = torch.cuda.device_count()\n",
        "print(n_devices)\n",
        "\n",
        "for i in range(n_devices):\n",
        "    print(torch.cuda.get_device_name(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw75jrFJgW79",
        "outputId": "44e3a02d-ba8e-4d28-e34d-4fd539a66ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNUaObwwgYXy"
      },
      "outputs": [],
      "source": [
        "model_name = \"Haaaaeun/kcbert_hatespeech\"\n",
        "# print(f\"  Model path = {args.model_name_or_path}\")\n",
        "# print(f\"  output_dir = {args.output_dir}\")\n",
        "\n",
        "label_list = [\"none\", \"hate\"]\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    model_name\n",
        "    )\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "      model_name\n",
        "    )\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1joMAg8glTy"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "  \"task\": \"hate-speech\",\n",
        "  \"data_dir\": \"data\",\n",
        "  \"ckpt_dir\": \"ckpt\",\n",
        "  \"train_file\": \"train.tsv\",\n",
        "  \"dev_file\": \"dev.csv\",\n",
        "  \"test_file\": \"val.tsv\",\n",
        "  \"max_seq_len\": 128,\n",
        "  \"num_train_epochs\": 5,\n",
        "  \"weight_decay\": 0.0,\n",
        "  \"gradient_accumulation_steps\": 1,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"warmup_proportion\": 0,\n",
        "  \"max_steps\": -1,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"no_cuda\": False,\n",
        "  \"model_name_or_path\": f\"{model_name}\",\n",
        "  \"output_dir\": f\"{model_name}-hate-speech-ckpt\",\n",
        "  \"seed\": 42,\n",
        "  \"train_batch_size\": 32,\n",
        "  \"eval_batch_size\": 64,\n",
        "  \"logging_steps\": 300,\n",
        "  \"save_steps\": 300,\n",
        "  \"learning_rate\": 5e-5,\n",
        "  \"evaluate_test_during_training\": True,\n",
        "  \"eval_all_checkpoints\": True,\n",
        "  \"save_optimizer\": False,\n",
        "  \"do_lower_case\": False,\n",
        "  \"do_train\": True,\n",
        "  \"do_eval\": True,\n",
        "  \"model_type\": \"roberta\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeMbhqZhgStX"
      },
      "outputs": [],
      "source": [
        "# GPU or CPU\n",
        "args[\"device\"] = \"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\"\n",
        "#GPU 사용\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csl4aENtcZob",
        "outputId": "a8fb487a-c88e-43e8-b734-cced75e9cd2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finish\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.to(args[\"device\"])\n",
        "print(\"Finish\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "VLZqe2e8Fyf9",
        "outputId": "665a39c1-1455-4033-c380-92626c5b84b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/19AmDlGex-hSZJyofrcVWB6uu3yQV-PSB/dataset/dataset/Soongsil-BERT/finetune/data/hate-speech\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       문장  혐오 여부\n",
              "0                                   정말 재밌다 연기도 좋고 디카프리오 짱      0\n",
              "1                         심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ      0\n",
              "2                               하지만 이니후빨러들은 이런거 관심 하나도 없음      1\n",
              "3                                       @착한아이임당 A4 용지 덮고?      1\n",
              "4       진짜 평점 믿으면 안된 다는 걸 현실로 보여주는 영화입니다. 네티즌,전문가 하나같이...      0\n",
              "...                                                   ...    ...\n",
              "189990  원작을 읽을 때 이런 건 절대 영상화하기 힘들다고 생각했는데 벤휘쇼의 연기와 더불어...      0\n",
              "189991                                   케석대 어깨 올라간거봐라 ㅋㅋ      1\n",
              "189992  @김짜꾸 day and night\\n\\nround the clock\\n\\nwitho...      1\n",
              "189993           로버트다우니주니어를 좋아해서 봤는데너무재밌게 봤던영화생각없이 볼때 딱좋음      0\n",
              "189994                         @익명_146173 개지랄병 병신좌좀새끼ㅋㅋㅋㅋ      1\n",
              "\n",
              "[189995 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5cd45cb-96ec-4bfe-bf54-3f30f0b267d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>혐오 여부</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>정말 재밌다 연기도 좋고 디카프리오 짱</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>하지만 이니후빨러들은 이런거 관심 하나도 없음</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@착한아이임당 A4 용지 덮고?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>진짜 평점 믿으면 안된 다는 걸 현실로 보여주는 영화입니다. 네티즌,전문가 하나같이...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189990</th>\n",
              "      <td>원작을 읽을 때 이런 건 절대 영상화하기 힘들다고 생각했는데 벤휘쇼의 연기와 더불어...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189991</th>\n",
              "      <td>케석대 어깨 올라간거봐라 ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189992</th>\n",
              "      <td>@김짜꾸 day and night\\n\\nround the clock\\n\\nwitho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189993</th>\n",
              "      <td>로버트다우니주니어를 좋아해서 봤는데너무재밌게 봤던영화생각없이 볼때 딱좋음</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189994</th>\n",
              "      <td>@익명_146173 개지랄병 병신좌좀새끼ㅋㅋㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>189995 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5cd45cb-96ec-4bfe-bf54-3f30f0b267d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5cd45cb-96ec-4bfe-bf54-3f30f0b267d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5cd45cb-96ec-4bfe-bf54-3f30f0b267d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/dataset/dataset/Soongsil-BERT/finetune/data/hate-speech'\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "# 데이터 준비\n",
        "test_file = \"dev.csv\"\n",
        "test = pd.read_csv(test_file)\n",
        "test = test.dropna(axis=0)\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# '혐오 여부' 열의 값을 1에서 0으로, 0에서 1로 바꾸기\n",
        "# test['혐오 여부'] = test['혐오 여부'].apply(lambda x: 0 if x == 1 else 1)\n",
        "\n",
        "# 변경된 데이터프레임을 'dev.csv' 파일로 저장 (덮어쓰기)\n",
        "# test.to_csv('dev.csv', index=False)\n",
        "\n",
        "# 결과 출력\n",
        "print(test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmB-s4TsIv02",
        "outputId": "04c6f02c-04b2-42e0-9837-eaa774e1349b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                       문장  혐오 여부\n",
            "0                                   정말 재밌다 연기도 좋고 디카프리오 짱      0\n",
            "1                         심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ      0\n",
            "2                               하지만 이니후빨러들은 이런거 관심 하나도 없음      1\n",
            "3                                       @착한아이임당 A4 용지 덮고?      1\n",
            "4       진짜 평점 믿으면 안된 다는 걸 현실로 보여주는 영화입니다. 네티즌,전문가 하나같이...      0\n",
            "...                                                   ...    ...\n",
            "189990  원작을 읽을 때 이런 건 절대 영상화하기 힘들다고 생각했는데 벤휘쇼의 연기와 더불어...      0\n",
            "189991                                   케석대 어깨 올라간거봐라 ㅋㅋ      1\n",
            "189992  @김짜꾸 day and night\\n\\nround the clock\\n\\nwitho...      1\n",
            "189993           로버트다우니주니어를 좋아해서 봤는데너무재밌게 봤던영화생각없이 볼때 딱좋음      0\n",
            "189994                         @익명_146173 개지랄병 병신좌좀새끼ㅋㅋㅋㅋ      1\n",
            "\n",
            "[189995 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HapHwNg7meQN",
        "outputId": "a2542c2f-442b-4f92-855d-a850fbd3ce93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'task': 'hate-speech',\n",
              " 'data_dir': 'data',\n",
              " 'ckpt_dir': 'ckpt',\n",
              " 'train_file': 'train.tsv',\n",
              " 'dev_file': 'dev.csv',\n",
              " 'test_file': 'val.tsv',\n",
              " 'max_seq_len': 128,\n",
              " 'num_train_epochs': 5,\n",
              " 'weight_decay': 0.0,\n",
              " 'gradient_accumulation_steps': 1,\n",
              " 'adam_epsilon': 1e-08,\n",
              " 'warmup_proportion': 0,\n",
              " 'max_steps': -1,\n",
              " 'max_grad_norm': 1.0,\n",
              " 'no_cuda': False,\n",
              " 'model_name_or_path': 'Haaaaeun/kcbert_hatespeech',\n",
              " 'output_dir': 'Haaaaeun/kcbert_hatespeech-hate-speech-ckpt',\n",
              " 'seed': 42,\n",
              " 'train_batch_size': 32,\n",
              " 'eval_batch_size': 64,\n",
              " 'logging_steps': 300,\n",
              " 'save_steps': 300,\n",
              " 'learning_rate': 5e-05,\n",
              " 'evaluate_test_during_training': True,\n",
              " 'eval_all_checkpoints': True,\n",
              " 'save_optimizer': False,\n",
              " 'do_lower_case': False,\n",
              " 'do_train': True,\n",
              " 'do_eval': True,\n",
              " 'model_type': 'roberta',\n",
              " 'device': 'cuda'}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOGpFpmJISuo"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def load_data(tokenizer):\n",
        "  file_to_read = args[\"dev_file\"]\n",
        "  input_path = os.path.join(args[\"data_dir\"], args[\"task\"], file_to_read)\n",
        "  print(f\"LOOKING AT {input_path}\")\n",
        "    \n",
        "  texts = []\n",
        "  labels = []\n",
        "    \n",
        "  with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    csv_reader = csv.reader(f)\n",
        "    next(csv_reader)  # 첫 번째 줄은 헤더이므로 건너뜁니다.\n",
        "        \n",
        "    for i, line in enumerate(csv_reader):\n",
        "      text_a = line[0]\n",
        "          \n",
        "      if text_a == \"\":\n",
        "        continue\n",
        "            \n",
        "      if i % 100000 == 0:\n",
        "        print(f\"[{i}] {line}\")\n",
        "            \n",
        "      texts.append({\n",
        "        \"text_a\": text_a,\n",
        "        \"text_b\": None,\n",
        "      })\n",
        "      labels.append(int(line[1]))\n",
        "  \n",
        "  # print(texts)\n",
        "  \n",
        "  # Convert text data to feature\n",
        "  batch_encoding = tokenizer(\n",
        "      [text[\"text_a\"] for text in texts],\n",
        "      max_length=args[\"max_seq_len\"],\n",
        "      truncation=True,\n",
        "      padding=True,\n",
        "      return_tensors='pt',\n",
        "      return_token_type_ids=True\n",
        "  )\n",
        "\n",
        "  features = []\n",
        "  for i in range(len(texts)):\n",
        "    input = {k: batch_encoding[k][i] for k in  batch_encoding}\n",
        "    if \"token_type_ids\" not in input:\n",
        "      input[\"token_type_ids\"] = [0] * len(input[\"input_ids\"])\n",
        "    features.append(input)\n",
        "\n",
        "  for i, feature in enumerate(features[:5]):\n",
        "    print(\"*** Example ***\")\n",
        "    print(\"input_ids: {}\".format(\" \".join([str(x) for x in feature[\"input_ids\"]])))\n",
        "    print(\"attention_mask: {}\".format(\" \".join([str(x) for x in feature[\"attention_mask\"]])))\n",
        "    print(\"token_type_ids: {}\".format(\" \".join([str(x) for x in feature[\"token_type_ids\"]])))\n",
        "    print(\"label: {}\".format(labels[i]))\n",
        "\n",
        "  # Convert feature to dataset\n",
        "  all_input_ids = batch_encoding[\"input_ids\"]\n",
        "  all_attention_mask = batch_encoding[\"attention_mask\"]\n",
        "  all_token_type_ids = batch_encoding[\"token_type_ids\"]\n",
        "  all_labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "  dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHtUkxPVK6Ca"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# Base Model (370M)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"jason9693/soongsil-bert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Cn2-dhoet5",
        "outputId": "d84c5565-8f9a-4531-be74-23fc7862b3b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ìķĪëħķ', 'ĠìĹĲ', '..?', 'Ġì§Ģê¸ĪìĿĢ', 'ĠíħĮìĬ¤íĬ¸', 'ì¤ĳ']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "tokenizer.tokenize(\"안녕 에..? 지금은 테스트중\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab1S96BalnyN"
      },
      "outputs": [],
      "source": [
        "batch_encoding = tokenizer(\n",
        "      [text for text in test], padding=True, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htj5Xad4ltE-",
        "outputId": "c751f335-91be-4c35-c62d-30fc25b827d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   0,  514,  409,    2,    1],\n",
              "        [   0, 4065,  474, 9159,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n",
              "        [1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "batch_encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "MrUNTT8cltHT",
        "outputId": "778f0c49-65d7-45d3-f374-004c00d2fde8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                문장  혐오 여부\n",
              "0            정말 재밌다 연기도 좋고 디카프리오 짱      1\n",
              "1  심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ      1\n",
              "2        하지만 이니후빨러들은 이런거 관심 하나도 없음      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-354511d9-a5b7-49b6-bcc2-59be1ec79e3a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>혐오 여부</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>정말 재밌다 연기도 좋고 디카프리오 짱</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>하지만 이니후빨러들은 이런거 관심 하나도 없음</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-354511d9-a5b7-49b6-bcc2-59be1ec79e3a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-354511d9-a5b7-49b6-bcc2-59be1ec79e3a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-354511d9-a5b7-49b6-bcc2-59be1ec79e3a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "test[:3]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6gzPLV9IH3-x",
        "outputId": "7755f2b6-6410-4f9c-b93a-ae0b02929484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       문장  혐오 여부\n",
              "0                                   정말 재밌다 연기도 좋고 디카프리오 짱      1\n",
              "1                         심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ      1\n",
              "2                               하지만 이니후빨러들은 이런거 관심 하나도 없음      0\n",
              "3                                       @착한아이임당 A4 용지 덮고?      0\n",
              "4       진짜 평점 믿으면 안된 다는 걸 현실로 보여주는 영화입니다. 네티즌,전문가 하나같이...      1\n",
              "...                                                   ...    ...\n",
              "189990  원작을 읽을 때 이런 건 절대 영상화하기 힘들다고 생각했는데 벤휘쇼의 연기와 더불어...      1\n",
              "189991                                   케석대 어깨 올라간거봐라 ㅋㅋ      0\n",
              "189992  @김짜꾸 day and night\\n\\nround the clock\\n\\nwitho...      0\n",
              "189993           로버트다우니주니어를 좋아해서 봤는데너무재밌게 봤던영화생각없이 볼때 딱좋음      1\n",
              "189994                         @익명_146173 개지랄병 병신좌좀새끼ㅋㅋㅋㅋ      0\n",
              "\n",
              "[189995 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0f8149c-43ed-490a-bd9c-63dd850e3777\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>혐오 여부</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>정말 재밌다 연기도 좋고 디카프리오 짱</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>하지만 이니후빨러들은 이런거 관심 하나도 없음</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@착한아이임당 A4 용지 덮고?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>진짜 평점 믿으면 안된 다는 걸 현실로 보여주는 영화입니다. 네티즌,전문가 하나같이...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189990</th>\n",
              "      <td>원작을 읽을 때 이런 건 절대 영상화하기 힘들다고 생각했는데 벤휘쇼의 연기와 더불어...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189991</th>\n",
              "      <td>케석대 어깨 올라간거봐라 ㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189992</th>\n",
              "      <td>@김짜꾸 day and night\\n\\nround the clock\\n\\nwitho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189993</th>\n",
              "      <td>로버트다우니주니어를 좋아해서 봤는데너무재밌게 봤던영화생각없이 볼때 딱좋음</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189994</th>\n",
              "      <td>@익명_146173 개지랄병 병신좌좀새끼ㅋㅋㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>189995 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0f8149c-43ed-490a-bd9c-63dd850e3777')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0f8149c-43ed-490a-bd9c-63dd850e3777 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0f8149c-43ed-490a-bd9c-63dd850e3777');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFK-ujlNltLr",
        "outputId": "5a7a9db6-95a0-443c-aad4-b9737bee94b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/19AmDlGex-hSZJyofrcVWB6uu3yQV-PSB/dataset/dataset/Soongsil-BERT/finetune\n",
            "LOOKING AT data/hate-speech/dev.csv\n",
            "[0] ['정말 재밌다 연기도 좋고 디카프리오 짱', '1']\n",
            "[100000] ['요즘 청와대 하는거 보면 진짜 암걸리겠다..문재인 대통령되고 나서 모든게 엉망이다', '0']\n",
            "*** Example ***\n",
            "input_ids: tensor(0) tensor(2082) tensor(2945) tensor(275) tensor(802) tensor(1174) tensor(3888) tensor(1909) tensor(1118) tensor(830) tensor(7653) tensor(2479) tensor(2) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1)\n",
            "attention_mask: tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "token_type_ids: tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "label: 1\n",
            "*** Example ***\n",
            "input_ids: tensor(0) tensor(640) tensor(10288) tensor(640) tensor(10288) tensor(8110) tensor(910) tensor(267) tensor(420) tensor(1888) tensor(8172) tensor(1745) tensor(624) tensor(353) tensor(2440) tensor(591) tensor(8195) tensor(348) tensor(809) tensor(358) tensor(1942) tensor(591) tensor(2) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1)\n",
            "attention_mask: tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "token_type_ids: tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "label: 1\n",
            "*** Example ***\n",
            "input_ids: tensor(0) tensor(1951) tensor(13740) tensor(975) tensor(1499) tensor(737) tensor(766) tensor(4932) tensor(2358) tensor(3796) tensor(3702) tensor(2) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1)\n",
            "attention_mask: tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "token_type_ids: tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "label: 0\n",
            "*** Example ***\n",
            "input_ids: tensor(0) tensor(36) tensor(12259) tensor(1738) tensor(665) tensor(460) tensor(3947) tensor(24) tensor(1941) tensor(289) tensor(4341) tensor(274) tensor(35) tensor(2) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1)\n",
            "attention_mask: tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "token_type_ids: tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "label: 0\n",
            "*** Example ***\n",
            "input_ids: tensor(0) tensor(1390) tensor(1153) tensor(812) tensor(1624) tensor(664) tensor(5233) tensor(12721) tensor(1211) tensor(2406) tensor(369) tensor(7478) tensor(1419) tensor(805) tensor(18) tensor(1335) tensor(15994) tensor(16) tensor(15055) tensor(10807) tensor(15493) tensor(6818) tensor(8344) tensor(10812) tensor(379) tensor(10301) tensor(8410) tensor(300) tensor(1419) tensor(5212) tensor(442) tensor(1153) tensor(812) tensor(15134) tensor(3670) tensor(18) tensor(2) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1)\n",
            "attention_mask: tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(1) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "token_type_ids: tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0) tensor(0)\n",
            "label: 1\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/dataset/dataset/Soongsil-BERT/finetune'\n",
        "test_dataset = load_data(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04wtx6FOltOM"
      },
      "outputs": [],
      "source": [
        "def evaluate(_model, _eval_dataset, mode, _global_step=None):\n",
        "  results = {}\n",
        "  eval_sampler = SequentialSampler(_eval_dataset)\n",
        "  eval_dataloader = DataLoader(_eval_dataset, sampler=eval_sampler, batch_size=args[\"eval_batch_size\"])\n",
        "\n",
        "  # Eval!\n",
        "  if _global_step != None:\n",
        "    print(f\"***** Running evaluation on {mode} dataset ({_global_step} step) *****\")\n",
        "  else:\n",
        "    print(f\"***** Running evaluation on {mode} dataset *****\")\n",
        "  print(f\"  Num examples = {len(_eval_dataset)}\")\n",
        "  print(f\"  Eval Batch size = {args['eval_batch_size']}\")\n",
        "  eval_loss = 0.0\n",
        "  nb_eval_steps = 0\n",
        "  preds = None\n",
        "  out_label_ids = None\n",
        "\n",
        "  # Dataloader [for]\n",
        "  for batch in progress_bar(eval_dataloader):\n",
        "  \n",
        "    batch = tuple(t.to(args[\"device\"]) for t in batch)\n",
        "    # if nb_eval_steps % 100000 == 0:\n",
        "      # print(nb_eval_steps, end=\" \")\n",
        "      # print(\"batch:\")\n",
        "      # print(batch)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      inputs = {\n",
        "          \"input_ids\": batch[0],\n",
        "          \"attention_mask\": batch[1],\n",
        "          \"labels\": batch[3]\n",
        "      }\n",
        "      if args[\"model_type\"] not in [\"distilkobert\", \"xlm-roberta\"]:\n",
        "        inputs[\"token_type_ids\"] = batch[2]  # Distilkobert, XLM-Roberta don't use segment_ids\n",
        "      # inputs[\"attention_type\"] = 'original_full'\n",
        "\n",
        "      outputs = _model(**inputs)\n",
        "      # if nb_eval_steps % 100000 == 0:\n",
        "        # print(\"outputs:\")\n",
        "        # print(outputs)\n",
        "\n",
        "      tmp_eval_loss, logits = outputs[:2]\n",
        "      # if nb_eval_steps % 100000 == 0:\n",
        "        # print(\"tmp_eval_loss, logits:\") \n",
        "        # print(tmp_eval_loss, logits)\n",
        "\n",
        "      eval_loss += tmp_eval_loss.mean().item()\n",
        "      \n",
        "    nb_eval_steps += 1\n",
        "\n",
        "    if preds is None:\n",
        "      preds = logits.detach().cpu().numpy()\n",
        "      out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "    else:\n",
        "      preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "      out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "  # End Dataloader [for]\n",
        "\n",
        "  eval_loss = eval_loss / nb_eval_steps\n",
        "  preds = np.argmax(preds, axis=1)\n",
        "  result = {\n",
        "      \"precision\": sklearn_metrics.precision_score(out_label_ids, preds, average=\"macro\"),\n",
        "      \"recall\": sklearn_metrics.recall_score(out_label_ids, preds, average=\"macro\"),\n",
        "      \"f1\": sklearn_metrics.f1_score(out_label_ids, preds, average=\"macro\")\n",
        "  }\n",
        "  results.update(result)\n",
        "\n",
        "  output_dir = os.path.join(args[\"output_dir\"], \"evaluate\")\n",
        "  if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "  output_eval_file = os.path.join(output_dir, f\"{mode}-{_global_step}.txt\" if _global_step else f\"{mode}.txt\")\n",
        "  with open(output_eval_file, \"w\") as f_w:\n",
        "    print(f\"***** Eval results on {mode} dataset *****\")\n",
        "    for key in sorted(results.keys()):\n",
        "      print(f\"  {key} = {str(results[key])}\")\n",
        "      f_w.write(f\"  {key} = {str(results[key])}\\n\")\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "N5gAcbYVTRDD",
        "outputId": "d1ede7e3-699c-49a2-886e-7ceb65d91884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Running evaluation on test dataset *****\n",
            "  Num examples = 189995\n",
            "  Eval Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='2969' class='' max='2969' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2969/2969 05:37&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attention type 'block_sparse' is not possible if sequence_length: 128 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Eval results on test dataset *****\n",
            "  f1 = 0.3457055066564746\n",
            "  precision = 0.6664615806930637\n",
            "  recall = 0.5003266676962037\n",
            "Evaluation results on test dataset:\n",
            "precision = 0.6664615806930637\n",
            "recall = 0.5003266676962037\n",
            "f1 = 0.3457055066564746\n"
          ]
        }
      ],
      "source": [
        "results = evaluate(model, test_dataset, mode=\"test\")\n",
        "print(\"Evaluation results on test dataset:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"{key} = {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HUG4fuLmDQy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "cdb7a77b-642f-4573-d6ec-94c3171a89ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-05c95fbfa550>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msteps_trained_in_current_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'output_dir'"
          ]
        }
      ],
      "source": [
        "# # Train!\n",
        "# print(\"***** Running training *****\")\n",
        "# print(f\"  Traning model_ = {args.model_name_or_path}\")\n",
        "# print(f\"  Num examples = {len(train_dataset)}\")\n",
        "# print(f\"  Num Epochs = {args.num_train_epochs}\")\n",
        "# print(f\"  Total train batch size = {args.train_batch_size}\")\n",
        "# print(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
        "# print(f\"  Total optimization steps = {t_total}\")\n",
        "# print(f\"  Logging steps = {args.logging_steps}\")\n",
        "# print(f\"  Save steps = { args.save_steps}\")\n",
        "\n",
        "global_step = 1\n",
        "epochs_trained = 0.0\n",
        "steps_trained_in_current_epoch = 0\n",
        "\n",
        "if os.path.exists(args.output_dir):\n",
        "  try:\n",
        "\n",
        "    print(\"  Find latest checkpoint\")\n",
        "    ckpts_suffix = [int(c.split(\"-\")[-1]) for c in os.listdir(args.output_dir) if c.startswith(\"checkpoint\")] \n",
        "    global_step = max(ckpts_suffix)\n",
        "    ckpt_path = os.path.join(args.output_dir, f\"checkpoint-{global_step}\" )\n",
        "    \n",
        "    model = AutoModelForSequenceClassification.from_pretrained(ckpt_path)\n",
        "    model.to(args.device)\n",
        "\n",
        "    epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "    steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "    print(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "    print(f\"  Continuing training from epoch {epochs_trained}\")\n",
        "    print(f\"  Continuing training from global step {global_step}\", )\n",
        "    print(f\"  Will skip the first {steps_trained_in_current_epoch} steps in the first epoch\")\n",
        "  except ValueError:\n",
        "    print(\"  Starting fine-tuning.\")\n",
        "\n",
        "tr_loss = 0.0\n",
        "\n",
        "model.zero_grad()\n",
        "mb = master_bar(range(int(args.num_train_epochs)))\n",
        "for epoch in mb:\n",
        "  epoch_iterator = progress_bar(train_dataloader, parent=mb)\n",
        "  # One epoch train\n",
        "  for step, batch in enumerate(epoch_iterator):\n",
        "    # Skip past any already trained steps if resuming training\n",
        "    if steps_trained_in_current_epoch > 0:\n",
        "      steps_trained_in_current_epoch -= 1\n",
        "      continue\n",
        "      \n",
        "    model.train()\n",
        "    batch = tuple(t.to(args.device) for t in batch)\n",
        "    inputs = {\n",
        "        \"input_ids\":batch[0],\n",
        "        \"attention_mask\": batch[1],\n",
        "        \"labels\": batch[3]\n",
        "    }\n",
        "\n",
        "    if args.model_type not in [\"distilkobert\", \"xlm-roberta\"]:\n",
        "      inputs[\"token_type_ids\"] = batch[2]  # Distilkobert, XLM-Roberta don't use segment_ids\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    loss = outputs[0]\n",
        "\n",
        "    if args.gradient_accumulation_steps > 1:\n",
        "      loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "    loss.backward()\n",
        "    tr_loss += loss.item()\n",
        "    # Accumulation \n",
        "    if (step + 1) % args.gradient_accumulation_steps == 0 or (\n",
        "        len(train_dataloader) <= args.gradient_accumulation_steps \n",
        "        and (step + 1) == len(train_dataloader)\n",
        "    ):\n",
        "      torch.nn.utils.clip_grad_norm(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      model.zero_grad()\n",
        "      global_step += 1\n",
        "\n",
        "      evaluate(model, dev_dataset, mode=\"dev\", _global_step=global_step)\n",
        "      \n",
        "\n",
        "      # Save model checkpoint\n",
        "      if args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "        output_dir = os.path.join(args.output_dir, f\"checkpoint-{global_step}\")\n",
        "        if not os.path.exists(output_dir):\n",
        "          os.makedirs(output_dir)\n",
        "        model_to_save = model.module if hasattr(model, \"module\") else model\n",
        "        model_to_save.save_pretrained(output_dir)\n",
        "\n",
        "        torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "        print(f\" Saving model checkpoint to {output_dir}\")\n",
        "\n",
        "        if args.save_optimizer:\n",
        "          torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "          torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "      # End Save model [if]\n",
        "    # End Accumulation [if]\n",
        "    \n",
        "    if args.max_steps > 0 and global_step > args.max_steps:\n",
        "      break\n",
        "  # End One epoch train [for]\n",
        "  mb.write(\"Epoch {} done\".format(epoch + 1))\n",
        "\n",
        "  if args.max_steps > 0 and global_step > args.max_steps:\n",
        "    break \n",
        "tr_loss = tr_loss / global_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEE5yCFPjwBW"
      },
      "outputs": [],
      "source": [
        "epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaE7j8Y8mFHk"
      },
      "outputs": [],
      "source": [
        "print(f\"global_step = {global_step}, average loss = {tr_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emYyxp8omFb7"
      },
      "outputs": [],
      "source": [
        "checkpoints = list(\n",
        "      os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + \"pytorch_model.bin\", recursive=True))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klfLGL6SmGw8"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for checkpoint in checkpoints:\n",
        "  _gloabl_step = checkpoint.split(\"-\")[-1]\n",
        "  eval_model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "  eval_model.to(args.device)\n",
        "  eval_model.eval()\n",
        "  result = evaluate(eval_model, test_dataset, mode=\"test\", _global_step=_gloabl_step)\n",
        "  result = dict((k +f\"_{_gloabl_step}\", v) for k, v in result.items())\n",
        "  results.update(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_SEhUrHmGzC"
      },
      "outputs": [],
      "source": [
        "for key in sorted(results.keys()):\n",
        "  print(f\"{key} = {results[key]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gil5zO0mG2u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRRzZFLOmG4p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}